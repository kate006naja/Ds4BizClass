{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering on Continuous Numeric Data\n",
    "\n",
    "Term 1 2019 - Instructor: Teerapong Leelanupab\n",
    "\n",
    "Teaching Assistant: Suttida Satjasunsern\n",
    "\n",
    "Credit: Dipanjan (DJ) Sarkar, [Continuous Numeric Data](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform/Engineer Continuous Numeric Attributes\n",
    "\n",
    "\n",
    "There is the need for engineering meaningful features from raw data is of utmost importance which can be understood and consumed by any machine learning, deep learning or statistical algorithms.\n",
    "\n",
    "**Feature engineering** is an essential part of building any intelligent system. Even though you have a lot of newer methodologies coming in like *deep learning( and *meta-heuristics* which aid in automated machine learning, each problem is domain specific and better features (suited to the problem) is often the deciding factor of the performance of your system. \n",
    "\n",
    "Feature Engineering is an art as well as a science and this is the reason Data Scientists often spend 70% of their time in the data preparation phase before modeling. This basically reinforces what we mentioned earlier about data scientists spending close to 70-80% of their time in engineering features which is a difficult and time-consuming process, requiring both domain knowledge and mathematical computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Features\n",
    "\n",
    "A *feature* is typically a specific representation on top of raw data, which is an individual, measurable attribute, typically depicted by a column in a dataset. Considering a generic two-dimensional dataset, each observation is depicted by a row and each feature by a column, which will have a specific value for an observation.\n",
    "\n",
    "![A generic dataset snapshot](images/Lab31_generic_data.png)\n",
    "<center><em>Fig. 1: A generic dataset snapshot</em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus like in the example in the figure above, each row typically indicates a feature vector and the entire set of features across all the observations forms a two-dimensional feature matrix also known as a feature-set. This is akin to data frames or spreadsheets representing two-dimensional data. Typically machine learning algorithms work with these numeric matrices or tensors and hence most feature engineering techniques deal with converting raw data into some numeric representations which can be easily understood by these algorithms.\n",
    "\n",
    "Features can be of two major types based on the dataset. Inherent **raw features** are obtained directly from the dataset with no extra data manipulation or engineering. **Derived or engineered features** are usually obtained from feature engineering, where we extract features from existing data attributes. A simple example would be creating a new feature “Age” from an employee dataset containing “Birthdate” by just subtracting their birth date from the current date.\n",
    "\n",
    "There are diverse types and formats of data including structured and unstructured data. In this article, we will discuss various feature engineering strategies for dealing with structured continuous numeric data. All these examples are a part of one of *Dipanjan Sarkar's* recent books ‘[*Practical Machine Learning with Python*](https://github.com/dipanjanS/practical-machine-learning-with-python)’ and you can access relevant datasets and code used in this article on [GitHub](https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch04_Feature_Engineering_and_Selection#chapter-4-feature-engineering-and-selection). A big shout out also goes to Gabriel Moreira who helped me by providing some excellent pointers on feature engineering techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering on Numeric Data\n",
    "\n",
    "Numeric data typically represents data in the form of scalar values depicting observations, recordings or measurements. Here, by numeric data, we mean **continuous data** and not discrete data which is typically represented as categorical data. Numeric data can also be represented as a vector of values where each value or entity in the vector can represent a specific feature. Integers and floats are the most common and widely used numeric data types for continuous numeric data. Even though numeric data can be directly fed into machine learning models, you would still need to engineer features which are relevant to the scenario, problem and domain before building a model. Hence the need for feature engineering still remains. Let’s leverage python and look at some strategies for feature engineering on numeric data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as spstats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Measures\n",
    "\n",
    "Like we mentioned earlier, raw numeric data can often be fed directly to machine learning models based on the context and data format. Raw measures are typically indicated using numeric variables directly as features without any form of transformation or engineering. Typically these features can indicate values or counts. Let’s load up one of our datasets, the [Pokémon](https://www.kaggle.com/abcsds/pokemon/data) dataset also available on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>Gen 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>Gen 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>Gen 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>Gen 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>Gen 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed Generation  Legendary  \n",
       "0       65       65     45      Gen 1      False  \n",
       "1       80       80     60      Gen 1      False  \n",
       "2      100      100     80      Gen 1      False  \n",
       "3      122      120     80      Gen 1      False  \n",
       "4       60       50     65      Gen 1      False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poke_df = pd.read_csv('data/Pokemon.csv', encoding='utf-8') \n",
    "poke_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokémon is a huge media franchise surrounding fictional characters called Pokémon which stands for pocket monsters. In short, you can think of them as fictional animals with superpowers! This dataset consists of these characters with various statistics for each character.\n",
    "\n",
    "##### Values\n",
    "\n",
    "If you closely observe the data frame snapshot in the above figure, you can see that several attributes represent numeric raw values which can be used directly. The following snippet depicts some of these features with more emphasis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HP  Attack  Defense\n",
       "0  45      49       49\n",
       "1  60      62       63\n",
       "2  80      82       83\n",
       "3  80     100      123\n",
       "4  39      52       43"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poke_df[['HP', 'Attack', 'Defense']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, you can directly use these attributes as features which are depicted in the above data frame. These include each Pokémon’s HP (Hit Points), Attack and Defense stats. In fact, we can also compute some basic statistical measures on these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69.258750</td>\n",
       "      <td>79.001250</td>\n",
       "      <td>73.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.534669</td>\n",
       "      <td>32.457366</td>\n",
       "      <td>31.183501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>230.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               HP      Attack     Defense\n",
       "count  800.000000  800.000000  800.000000\n",
       "mean    69.258750   79.001250   73.842500\n",
       "std     25.534669   32.457366   31.183501\n",
       "min      1.000000    5.000000    5.000000\n",
       "25%     50.000000   55.000000   50.000000\n",
       "50%     65.000000   75.000000   70.000000\n",
       "75%     80.000000  100.000000   90.000000\n",
       "max    255.000000  190.000000  230.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poke_df[['HP', 'Attack', 'Defense']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poke_df[(poke_df.Legendary == True) & (poke_df.Attack <= 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this you can get a good idea about statistical measures in these features like count, average, standard deviation and quartiles.\n",
    "\n",
    "#### Counts\n",
    "\n",
    "Another form of raw measures include features which represent frequencies, counts or occurrences of specific attributes. Let’s look at a sample of data from the [millionsong](http://millionsongdataset.com/) dataset which depicts counts or frequencies of songs which have been heard by various users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>listen_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6b799f34a204bd928ea014c243ddad6d0be4f8f</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b41ead730ac14f6b6717b9cf8859d5579f3f8d4d</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c84359a164b161496d05282707cecbd50adbfc4</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779b5908593756abb6ff7586177c966022668b06</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd88ea94f605a63d9fc37a214127e3f00e85e42d</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68f0359a2f1cedb0d15c98d88017281db79f9bc6</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116a4c95d63623a967edf2f3456c90ebbf964e6f</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45544491ccfcdc0b0803c34f201a6287ed4e30f8</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e701a24d9b6c59f5ac37ab28462ca82470e27cfb</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>edc8b7b1fd592a3b69c3d823a742e1a064abec95</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id             song_id  \\\n",
       "0  b6b799f34a204bd928ea014c243ddad6d0be4f8f  SOBONKR12A58A7A7E0   \n",
       "1  b41ead730ac14f6b6717b9cf8859d5579f3f8d4d  SOBONKR12A58A7A7E0   \n",
       "2  4c84359a164b161496d05282707cecbd50adbfc4  SOBONKR12A58A7A7E0   \n",
       "3  779b5908593756abb6ff7586177c966022668b06  SOBONKR12A58A7A7E0   \n",
       "4  dd88ea94f605a63d9fc37a214127e3f00e85e42d  SOBONKR12A58A7A7E0   \n",
       "5  68f0359a2f1cedb0d15c98d88017281db79f9bc6  SOBONKR12A58A7A7E0   \n",
       "6  116a4c95d63623a967edf2f3456c90ebbf964e6f  SOBONKR12A58A7A7E0   \n",
       "7  45544491ccfcdc0b0803c34f201a6287ed4e30f8  SOBONKR12A58A7A7E0   \n",
       "8  e701a24d9b6c59f5ac37ab28462ca82470e27cfb  SOBONKR12A58A7A7E0   \n",
       "9  edc8b7b1fd592a3b69c3d823a742e1a064abec95  SOBONKR12A58A7A7E0   \n",
       "\n",
       "            title  listen_count  \n",
       "0  You're The One             2  \n",
       "1  You're The One             0  \n",
       "2  You're The One             0  \n",
       "3  You're The One             0  \n",
       "4  You're The One             0  \n",
       "5  You're The One             0  \n",
       "6  You're The One            17  \n",
       "7  You're The One             0  \n",
       "8  You're The One            68  \n",
       "9  You're The One             0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popsong_df = pd.read_csv('data/song_views.csv',  encoding='utf-8')\n",
    "popsong_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite evident from the above snapshot that the listen_count field can be used directly as a frequency\\count based numeric feature.\n",
    "\n",
    "#### Binarization\n",
    "\n",
    "Often raw frequencies or counts may not be relevant for building a model based on the problem which is being solved. For instance if I’m building a recommendation system for song recommendations, I would just want to know if a person is interested or has listened to a particular song. This doesn’t require the number of times a song has been listened to since I am more concerned about the various songs he\\she has listened to. In this case, a binary feature is preferred as opposed to a count based feature. We can binarize our `listen_count` field as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>listen_count</th>\n",
       "      <th>watched</th>\n",
       "      <th>pd_watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6b799f34a204bd928ea014c243ddad6d0be4f8f</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b41ead730ac14f6b6717b9cf8859d5579f3f8d4d</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c84359a164b161496d05282707cecbd50adbfc4</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779b5908593756abb6ff7586177c966022668b06</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd88ea94f605a63d9fc37a214127e3f00e85e42d</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68f0359a2f1cedb0d15c98d88017281db79f9bc6</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116a4c95d63623a967edf2f3456c90ebbf964e6f</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45544491ccfcdc0b0803c34f201a6287ed4e30f8</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e701a24d9b6c59f5ac37ab28462ca82470e27cfb</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>edc8b7b1fd592a3b69c3d823a742e1a064abec95</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id             song_id  \\\n",
       "0  b6b799f34a204bd928ea014c243ddad6d0be4f8f  SOBONKR12A58A7A7E0   \n",
       "1  b41ead730ac14f6b6717b9cf8859d5579f3f8d4d  SOBONKR12A58A7A7E0   \n",
       "2  4c84359a164b161496d05282707cecbd50adbfc4  SOBONKR12A58A7A7E0   \n",
       "3  779b5908593756abb6ff7586177c966022668b06  SOBONKR12A58A7A7E0   \n",
       "4  dd88ea94f605a63d9fc37a214127e3f00e85e42d  SOBONKR12A58A7A7E0   \n",
       "5  68f0359a2f1cedb0d15c98d88017281db79f9bc6  SOBONKR12A58A7A7E0   \n",
       "6  116a4c95d63623a967edf2f3456c90ebbf964e6f  SOBONKR12A58A7A7E0   \n",
       "7  45544491ccfcdc0b0803c34f201a6287ed4e30f8  SOBONKR12A58A7A7E0   \n",
       "8  e701a24d9b6c59f5ac37ab28462ca82470e27cfb  SOBONKR12A58A7A7E0   \n",
       "9  edc8b7b1fd592a3b69c3d823a742e1a064abec95  SOBONKR12A58A7A7E0   \n",
       "\n",
       "            title  listen_count  watched  pd_watched  \n",
       "0  You're The One             2        1           1  \n",
       "1  You're The One             0        0           0  \n",
       "2  You're The One             0        0           0  \n",
       "3  You're The One             0        0           0  \n",
       "4  You're The One             0        0           0  \n",
       "5  You're The One             0        0           0  \n",
       "6  You're The One            17        1           1  \n",
       "7  You're The One             0        0           0  \n",
       "8  You're The One            68        1           1  \n",
       "9  You're The One             0        0           0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watched = np.array(popsong_df['listen_count'])\n",
    "watched[watched >= 1] =1\n",
    "popsong_df['watched'] = watched\n",
    "popsong_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also use scikit-learn's `Binarizer` class here from its `preprocessing` module to perform the same task instead of `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>listen_count</th>\n",
       "      <th>watched</th>\n",
       "      <th>pd_watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6b799f34a204bd928ea014c243ddad6d0be4f8f</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b41ead730ac14f6b6717b9cf8859d5579f3f8d4d</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c84359a164b161496d05282707cecbd50adbfc4</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779b5908593756abb6ff7586177c966022668b06</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd88ea94f605a63d9fc37a214127e3f00e85e42d</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68f0359a2f1cedb0d15c98d88017281db79f9bc6</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116a4c95d63623a967edf2f3456c90ebbf964e6f</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45544491ccfcdc0b0803c34f201a6287ed4e30f8</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e701a24d9b6c59f5ac37ab28462ca82470e27cfb</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>edc8b7b1fd592a3b69c3d823a742e1a064abec95</td>\n",
       "      <td>SOBONKR12A58A7A7E0</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id             song_id  \\\n",
       "0  b6b799f34a204bd928ea014c243ddad6d0be4f8f  SOBONKR12A58A7A7E0   \n",
       "1  b41ead730ac14f6b6717b9cf8859d5579f3f8d4d  SOBONKR12A58A7A7E0   \n",
       "2  4c84359a164b161496d05282707cecbd50adbfc4  SOBONKR12A58A7A7E0   \n",
       "3  779b5908593756abb6ff7586177c966022668b06  SOBONKR12A58A7A7E0   \n",
       "4  dd88ea94f605a63d9fc37a214127e3f00e85e42d  SOBONKR12A58A7A7E0   \n",
       "5  68f0359a2f1cedb0d15c98d88017281db79f9bc6  SOBONKR12A58A7A7E0   \n",
       "6  116a4c95d63623a967edf2f3456c90ebbf964e6f  SOBONKR12A58A7A7E0   \n",
       "7  45544491ccfcdc0b0803c34f201a6287ed4e30f8  SOBONKR12A58A7A7E0   \n",
       "8  e701a24d9b6c59f5ac37ab28462ca82470e27cfb  SOBONKR12A58A7A7E0   \n",
       "9  edc8b7b1fd592a3b69c3d823a742e1a064abec95  SOBONKR12A58A7A7E0   \n",
       "\n",
       "            title  listen_count  watched  pd_watched  \n",
       "0  You're The One             2        1           1  \n",
       "1  You're The One             0        0           0  \n",
       "2  You're The One             0        0           0  \n",
       "3  You're The One             0        0           0  \n",
       "4  You're The One             0        0           0  \n",
       "5  You're The One             0        0           0  \n",
       "6  You're The One            17        1           1  \n",
       "7  You're The One             0        0           0  \n",
       "8  You're The One            68        1           1  \n",
       "9  You're The One             0        0           0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#bn = Binarizer(threshold = 0.9)\n",
    "#pd_watched = bn.transform([popsong_df['listen_count']])[0]\n",
    "popsong_df['pd_watched'] = Binarizer(threshold = 0.9).transform([popsong_df['listen_count']])[0]\n",
    "\n",
    "popsong_df.head(10)\n",
    "#from sklearn.preprocessing import Binarizer\n",
    "#bn = Binarizer(threshold=0.9)\n",
    "#pd_watched = bn.transform([popsong_df['listen_count']])[0]\n",
    "#popsong_df['pd_watched'] = pd_watched\n",
    "#popsong_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clearly see from the above snapshot that `both the methods` have produced `the same result`. Thus we get a binarized feature indicating if the song was listened to or not by each user which can be then further used in a relevant model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rounding\n",
    "\n",
    "Often when dealing with continuous numeric attributes like proportions or percentages, we may not need the raw values having a high amount of precision. Hence it often makes sense to round off these high precision percentages into numeric integers. These integers can then be directly used as raw values or even as categorical (discrete-class based) features. Let’s try applying this concept in a dummy dataset depicting store items and their popularity percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>pop_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it_01345</td>\n",
       "      <td>0.98324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it_03431</td>\n",
       "      <td>0.56123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it_04572</td>\n",
       "      <td>0.12098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it_98021</td>\n",
       "      <td>0.35476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it_01298</td>\n",
       "      <td>0.92101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it_90120</td>\n",
       "      <td>0.81212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it_10123</td>\n",
       "      <td>0.56502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id  pop_percent\n",
       "0  it_01345      0.98324\n",
       "1  it_03431      0.56123\n",
       "2  it_04572      0.12098\n",
       "3  it_98021      0.35476\n",
       "4  it_01298      0.92101\n",
       "5  it_90120      0.81212\n",
       "6  it_10123      0.56502"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_popularity = pd.read_csv('data/item_popularity.csv',  encoding='utf-8')\n",
    "items_popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the below examples, you can guess that we tried two forms of rounding. The features depict the item popularities now both on a scale of 1–10 and on a scale of 1–100. You can use these values both as numerical or categorical features based on the scenario and problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>pop_percent</th>\n",
       "      <th>popularity_scale_10</th>\n",
       "      <th>popularity_scale_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it_01345</td>\n",
       "      <td>0.98324</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it_03431</td>\n",
       "      <td>0.56123</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it_04572</td>\n",
       "      <td>0.12098</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it_98021</td>\n",
       "      <td>0.35476</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it_01298</td>\n",
       "      <td>0.92101</td>\n",
       "      <td>9</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it_90120</td>\n",
       "      <td>0.81212</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it_10123</td>\n",
       "      <td>0.56502</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id  pop_percent  popularity_scale_10  popularity_scale_100\n",
       "0  it_01345      0.98324                   10                    98\n",
       "1  it_03431      0.56123                    6                    56\n",
       "2  it_04572      0.12098                    1                    12\n",
       "3  it_98021      0.35476                    4                    35\n",
       "4  it_01298      0.92101                    9                    92\n",
       "5  it_90120      0.81212                    8                    81\n",
       "6  it_10123      0.56502                    6                    57"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_popularity['popularity_scale_10'] = np.array(np.round((items_popularity['pop_percent'] * 10)),dtype='int')\n",
    "items_popularity['popularity_scale_100'] = np.array(np.round((items_popularity['pop_percent'] * 100)), dtype='int')\n",
    "items_popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactions\n",
    "Supervised machine learning models usually try to model the output responses (discrete classes or continuous values) as a function of the input feature variables. For example, a simple linear regression equation can be depicted as\n",
    "\n",
    "\n",
    "$y=c_{1}x_{1}+c_{2}x_{2}+...+c_{n}x_{n}$ where the input features are depicted by variables $\\{x_{1},x_{2},...,x_{n}\\}$ having weights or coefficients denoted by $\\{c_{1},c_{2},...,c_{n}\\}$ respectively and the goal is to predict the response $y$.\n",
    "\n",
    "<br />\n",
    "\n",
    "In this case, this simple linear model depicts the relationship between the output and inputs, purely based on the individual, separate input features.\n",
    "\n",
    "However, often in several real-world scenarios, it makes sense to also try and capture the interactions between these feature variables as a part of the input feature set. A simple depiction of the extension of the above linear regression formulation with interaction features would be\n",
    "\n",
    "\n",
    "$y=c_{1}x_{1}+c_{2}x_{2}+...+c_{n}x_{n}+c_{11}x_{1}^{2}+c_{22}x_{2}^{2}+c_{12}x_{1}x_{2}+...$ where the features represented by $\\{x_{1},x_{2},x_{1}^{2},x_{2}^{2},x_{1}x_{2},...\\}$ denote the interaction features. Let’s try engineering some interaction features on our **Pokémon** dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attack  Defense\n",
       "0      49       49\n",
       "1      62       63\n",
       "2      82       83\n",
       "3     100      123\n",
       "4      52       43"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atk_def = poke_df[['Attack', 'Defense']]\n",
    "atk_def.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output data frame, we can see that we have two numeric (continuous) features, `Attack` and `Defence`. We will now build features up to the 2nd degree by leveraging scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   49.,    49.,  2401.,  2401.,  2401.],\n",
       "       [   62.,    63.,  3844.,  3906.,  3969.],\n",
       "       [   82.,    83.,  6724.,  6806.,  6889.],\n",
       "       ...,\n",
       "       [  110.,    60., 12100.,  6600.,  3600.],\n",
       "       [  160.,    60., 25600.,  9600.,  3600.],\n",
       "       [  110.,   120., 12100., 13200., 14400.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "res=pf.fit_transform(atk_def)\n",
    "res\n",
    "# 0 = atk, 1 = def, 2 = atk**2, 3 = ?, 4 = def ** 2\n",
    "\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#pf = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "#res = pf.fit_transform(atk_def)\n",
    "#res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above feature matrix depicts a total of five features including the new interaction features. We can see the degree of each feature (i.e., $x_1$ and $x_2$) in the above matrix, $\\{ x_1, x_2, x_1^2, x_1x_2, x_2^2\\}$, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pf.powers_, columns=['Attack_degree', 'Defense_degree'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above output, we now know what each feature actually represents from the degrees depicted here. Armed with this knowledge, we can assign a name to each feature now as follows. This is just for ease of understanding and you should name your features with better, easy to access and simple names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intr_features = pd.DataFrame(res, columns=['Attack', 'Defense', 'Attack^2', 'Attack x Defense', 'Defense^2'])\n",
    "intr_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the above data frame represents our original features along with their interaction features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning\n",
    "The problem of working with raw, continuous numeric features is that often the distribution of values in these features will be skewed. This signifies that some values will occur quite frequently while some will be quite rare. Besides this, there is also another problem of the varying range of values in any of these features. For instance view counts of specific music videos could be abnormally large ([Despacito](https://www.youtube.com/watch?v=kJQP7kiw5Fk) we’re looking at you!) and some could be really small. Directly using these features can cause a lot of issues and adversely affect the model. Hence there are strategies to deal with this, which include binning and transformations.\n",
    "\n",
    "`Binning`, also known as `quantization` is used for transforming continuous numeric features into discrete ones (categories). These discrete values or numbers can be thought of as categories or bins into which the raw, continuous numeric values are binned or grouped into. Each bin represents a specific degree of intensity and hence a specific range of continuous numeric values fall into it. Specific strategies of binning data include fixed-width and adaptive binning. Let’s use a subset of data from a dataset extracted from the [2016 FreeCodeCamp Developer\\Coder survey](https://github.com/freeCodeCamp/2016-new-coder-survey) which talks about various attributes pertaining to coders and software developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_survey_df = pd.read_csv('data/fcc_2016_coder_survey_subset.csv', encoding='utf-8')\n",
    "fcc_survey_df[['ID.x', 'EmploymentField', 'Age', 'Income']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID.x variable is basically a unique identifier for each coder\\developer who took the survey and the other fields are pretty self-explanatory.\n",
    "\n",
    "#### Fixed-Width Binning\n",
    "Just like the name indicates, in fixed-width binning, we have specific fixed widths for each of the bins which are usually pre-defined by the user analyzing the data. Each bin has a pre-fixed range of values which should be assigned to that bin on the basis of some domain knowledge, rules or constraints. Binning based on rounding is one of the ways, where you can use the rounding operation which we discussed earlier to bin raw values.\n",
    "\n",
    "Let’s now consider the `Age` feature from the coder survey dataset and look at its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Age'].hist(color='#A9C5D3', edgecolor='black', grid=False)\n",
    "ax.set_title('Developer Age Histogram', fontsize=12)\n",
    "ax.set_xlabel('Age', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above histogram depicting developer ages is slightly right skewed as expected (lesser aged developers). We will now assign these raw age values into specific bins based on the following scheme\n",
    "\n",
    "![Fixed Bin Across Different Age Ranges 10](images/Lab31_fixedbin_10.png)\n",
    "<center><em>Fig. 2: Fixed Bin Across Different Age Ranges with the Bin Size of 10</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily do this using what we learnt in the *Rounding* section earlier where we round off these raw age values by taking the floor value after dividing it by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_survey_df['Age_bin_round'] = np.array(np.floor(np.array(fcc_survey_df['Age']) / 10.))\n",
    "fcc_survey_df[['ID.x', 'Age', 'Age_bin_round']].iloc[1071:1076]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the corresponding bins for each age have been assigned based on rounding. But what if we need more flexibility? What if we want to decide and fix the bin widths based on our own rules\\logic? Binning based on custom ranges will help us achieve this. Let’s define some custom age ranges for binning developer ages using the following scheme.\n",
    "\n",
    "![Fixed Bin Across Different Age Ranges 15](images/Lab31_fixedbin_15.png)\n",
    "<center><em>Fig. 3: Fixed Bin Across Different Age Ranges with the Custom Mix Bin Sizes of 15 and 25 and Starting Bin Index from 1</em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ranges = [0, 15, 30, 45, 60, 75, 100]\n",
    "bin_names = [1, 2, 3, 4, 5, 6]\n",
    "fcc_survey_df['Age_bin_custom_range'] = pd.cut(\n",
    "                                           np.array(\n",
    "                                              fcc_survey_df['Age']), \n",
    "                                              bins=bin_ranges)\n",
    "fcc_survey_df['Age_bin_custom_label'] = pd.cut(\n",
    "                                           np.array(\n",
    "                                              fcc_survey_df['Age']), \n",
    "                                              bins=bin_ranges,            \n",
    "                                              labels=bin_names)\n",
    "# view the binned features \n",
    "fcc_survey_df[['ID.x', 'Age', 'Age_bin_round', \n",
    "               'Age_bin_custom_range',   \n",
    "               'Age_bin_custom_label']].iloc[1071:1076]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Binning\n",
    "<font color='red'>The drawback in using fixed-width binning is that due to us manually deciding the bin ranges</font>, we can end up with irregular bins which are not uniform based on the number of data points or values which fall in each bin. Some of the bins might be densely populated and some of them might be sparsely populated or even empty! Adaptive binning is a safer strategy in these scenarios where we let the data speak for itself! That’s right, we use the data distribution itself to decide our bin ranges.\n",
    "\n",
    "**Quantile based binning** is a good strategy to use for adaptive binning. Quantiles are specific values or cut-points which help in partitioning the continuous valued distribution of a specific numeric field into discrete contiguous bins or intervals. Thus, *q-Quantiles* help in partitioning a numeric attribute into *q* equal partitions. Popular examples of quantiles include the *2-Quantile* known as the *median* which divides the data distribution into two equal bins, *4-Quantiles* known as the *quartiles* which divide the data into 4 equal bins and *10-Quantiles* also known as the *deciles* which create 10 equal width bins. Let’s now look at the data distribution for the developer `Income` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Income'].hist(bins=30, color='#A9C5D3', edgecolor='black', grid=False)\n",
    "ax.set_title('Developer Income Histogram', fontsize=12)\n",
    "ax.set_xlabel('Developer Income', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above distribution depicts a right skew in the income with lesser developers earning more money and vice versa. Let’s take a **4-Quantile** or a *quartile* based adaptive binning `scheme`. We can obtain the quartiles easily as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_list = [0, .25, .5, .75, 1.]\n",
    "quantiles = fcc_survey_df['Income'].quantile(quantile_list)\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now visualize these quantiles in the original distribution histogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Income'].hist(bins=30, color='#A9C5D3', edgecolor='black', grid=False)\n",
    "for quantile in quantiles:\n",
    "    qvl = plt.axvline(quantile, color='r')\n",
    "ax.legend([qvl], ['Quantiles'], fontsize=10)\n",
    "ax.set_title('Developer Income Histogram with Quantiles', fontsize=12)\n",
    "ax.set_xlabel('Developer Income', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red lines in the distribution above depict the quartile values and our potential bins. Let’s now leverage this knowledge to build our quartile based binning scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_labels = ['0-25Q', '25-50Q', '50-75Q', '75-100Q']\n",
    "fcc_survey_df['Income_quantile_range'] = pd.qcut(\n",
    "                                            fcc_survey_df['Income'], \n",
    "                                            q=quantile_list)\n",
    "fcc_survey_df['Income_quantile_label'] = pd.qcut(\n",
    "                                            fcc_survey_df['Income'], \n",
    "                                            q=quantile_list,       \n",
    "                                            labels=quantile_labels)\n",
    "\n",
    "fcc_survey_df[['ID.x', 'Age', 'Income', 'Income_quantile_range', \n",
    "               'Income_quantile_label']].iloc[4:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give you a good idea of how quantile based adaptive binning works. An important point to remember here is that the resultant outcome of binning leads to discrete valued categorical features and you might need an additional step of feature engineering on the categorical data before using it in any model. We will cover feature engineering strategies for categorical data shortly in the next part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Transformations\n",
    "\n",
    "We talked about the adverse effects of skewed data distributions briefly earlier. Let’s look at a different strategy of feature engineering now by making use of statistical or mathematical transformations.We will look at the `Log` transform as well as the `Box-Cox` transform. Both of these transform functions belong to the `Power Transform` family of functions, typically used to create monotonic data transformations. Their main significance is that they help in stabilizing variance, adhering closely to the normal distribution and making the data independent of the mean based on its distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Transform\n",
    "\n",
    "The log transform belongs to the power transform family of functions. This function can be mathematically represented as\n",
    "$y=\\textrm{log}_b(x)$ which reads as log of $x$ to the base $b$ is equal to $y$. This can then be translated into $b^y=x$ which indicates as to what power must the base $b$ be raised to in order to get $x$. The natural logarithm uses $b$=$e$ where $e$ = 2.71828 popularly known as Euler’s number. You can also use base $b$=10 used popularly in the decimal system.\n",
    "\n",
    "\n",
    "`Log transforms are useful when applied to skewed distributions as they tend to expand the values which fall in the range of lower magnitudes and tend to compress or reduce the values which fall in the range of higher magnitudes.` This tends to make the skewed distribution as normal-like as possible. Let’s use log transform on our **developer Income** feature which we used earlier.\n",
    "\n",
    "First, let's look at the data distribution on the developer Incomefield now before applying the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_mean = np.round(np.mean(fcc_survey_df['Income']), 2)\n",
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Income'].hist(bins=30, color='#A9C5D3', \n",
    "                                 edgecolor='black', grid=False)\n",
    "plt.axvline(income_mean, color='r')\n",
    "ax.set_title('Developer Income Histogram', \n",
    "             fontsize=12)\n",
    "ax.set_xlabel('Developer Income', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.text(150000, 650, r'$\\mu$='+str(income_mean), fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_survey_df['Income_log'] = np.log((1+ fcc_survey_df['Income']))\n",
    "fcc_survey_df[['ID.x', 'Age', 'Income', 'Income_log']].iloc[4:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Income_log field depicts the transformed feature after log transformation. Let’s look at the data distribution on this transformed field now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_log_mean = np.round(np.mean(fcc_survey_df['Income_log']), 2)\n",
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Income_log'].hist(bins=30, color='#A9C5D3', \n",
    "                                 edgecolor='black', grid=False)\n",
    "plt.axvline(income_log_mean, color='r')\n",
    "ax.set_title('Developer Income Histogram after Log Transform', \n",
    "             fontsize=12)\n",
    "ax.set_xlabel('Developer Income (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.text(11.5, 450, r'$\\mu$='+str(income_log_mean), fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above plot, we can clearly see that the distribution is more normal-like or gaussian as compared to the skewed distribution on the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box-Cox Transform\n",
    "\n",
    "The [Box-Cox](https://lonewritings.github.io/notes/2016/05/18/box-cox-transformation.html) transform is another popular function belonging to the power transform family of functions. This function has a pre-requisite that the numeric values to be transformed must be positive (similar to what log transform expects). In case they are negative, shifting using a constant value helps. Mathematically, the Box-Cox transform function can be denoted as follows.\n",
    "\n",
    "<center>\n",
    " $y = f(x,\\lambda)= x^{ \\lambda  } = \\begin{Bmatrix}\n",
    " \\frac { { x }^{ \\lambda} - 1 }{ \\lambda} & : \\lambda > 0\\\\ \n",
    " \\textrm{log}_e(x) & : \\lambda = 0\n",
    "\\end{Bmatrix} $ \n",
    "</center>\n",
    "\n",
    "Such that the resulted transformed output $y$ is a function of input $x$ and the transformation parameter $\\lambda$ such that when $\\lambda = 0$, the resultant transform is the natural log transform which we discussed earlier. The optimal value of $\\lambda$ is usually determined using a maximum likelihood or log-likelihood estimation. Let’s now apply the Box-Cox transform on our developer income feature. First we get the **optimal lambda value** from the data distribution by removing the non-null values as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = np.array(fcc_survey_df['Income'])\n",
    "income_clean = income[~np.isnan(income)]\n",
    "l, opt_lambda = spstats.boxcox(income_clean)\n",
    "print('Optimal lambda value:', opt_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the optimal $\\lambda$ value, let us use the Box-Cox transform for two values of $\\lambda$ such that $\\lambda = 0$ and $\\lambda = \\lambda$ (optimal) and transform the developer Income feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_survey_df['Income_boxcox_lambda_0'] = spstats.boxcox(\n",
    "                                        (1+fcc_survey_df['Income']), \n",
    "                                          lmbda=0)\n",
    "fcc_survey_df['Income_boxcox_lambda_opt'] = spstats.boxcox(\n",
    "                                            fcc_survey_df['Income'], \n",
    "                                              lmbda=opt_lambda)\n",
    "\n",
    "fcc_survey_df[['ID.x', 'Age', 'Income', 'Income_log', \n",
    "               'Income_boxcox_lambda_0',       \n",
    "               'Income_boxcox_lambda_opt']].iloc[4:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformed features are depicted in the above data frame. Just like we expected, `Income_log` and `Income_boxcox_lamba_0` have the same values. Let’s look at the distribution of the transformed Income feature after transforming with the optimal $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_boxcox_mean = np.round(\n",
    "                      np.mean(\n",
    "                       fcc_survey_df['Income_boxcox_lambda_opt']),2)\n",
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Income_boxcox_lambda_opt'].hist(bins=30, \n",
    "                     color='#A9C5D3', edgecolor='black', grid=False)\n",
    "plt.axvline(income_boxcox_mean, color='r')\n",
    "ax.set_title('Developer Income Histogram after Box–Cox Transform', \n",
    "             fontsize=12)\n",
    "ax.set_xlabel('Developer Income (Box–Cox transform)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.text(24, 450, r'$\\mu$='+str(income_boxcox_mean), fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution looks more normal-like similar to what we obtained after the *log* transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Feature engineering is a very important aspect of machine learning and data science and should never be ignored. While we have automated feature engineering methodologies like deep learning as well as automated machine learning frameworks like AutoML (which still stresses that it requires good features to work well!). Feature engineering is here to stay and even some of these automated methodologies often require specific engineered features based on the data type, domain and the problem to be solved.\n",
    "\n",
    "We looked at popular strategies for feature engineering on continuous numeric data in this article. In the next part, we will look at popular strategies for dealing with discrete, categorical data and then move on to unstructured data types in future articles. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
